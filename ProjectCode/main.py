# -*- coding: utf-8 -*-
"""ProjectDepression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wrp6GMNjScB1by5_GOBIJq1vIMwVDoa_
"""

#Necessary to build Shappley Additive Explanations
!pip install shap

#Libraries helping with file retrival
import os
from os import listdir
from os.path import isfile, join

#Visualization and data manipulation libraries
import matplotlib.pyplot as plt
import scipy.io
from scipy.signal import butter, lfilter
import pandas as pd
import numpy as np
import seaborn as sns
sns.set(font_scale=1.2)

#Model development and understanding
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.inspection import permutation_importance
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
import shap

from google.colab import drive
drive.mount('/content/drive')

#Import ERP dataframe
df_erp = pd.read_csv('/content/ERP_Summary_limited.csv')
#Import Resting dataframe
df_resting = pd.read_csv('/content/Resting_Summary_limited.csv')
#Import demographics table
df_demog = pd.read_excel('/content/subjects_information_EEG_128channels_resting_lanzhou_2015.xlsx',sheet_name = 'Sheet1')

"""# New Section"""

#Lets first create a patient identifier key
df_erp['patient_identifier']= [i[:8] for i in df_erp['patient_identifier']]
df_erp['patient_identifier'] = df_erp['patient_identifier'].astype(int)
df_resting['patient_identifier']= [i[:8] for i in df_resting['patient_identifier']]
df_resting['patient_identifier'] = df_resting['patient_identifier'].astype(int)

#Combining the datasets
#Step - 1: Merge Demog Data
intermediate_df = pd.merge(df_erp,df_demog,left_on = 'patient_identifier',right_on = 'subject id',how ='inner')
#Merge Resting Data
df = pd.merge(intermediate_df,df_resting,left_on = 'patient_identifier',right_on = 'patient_identifier',how ='inner')
#Set Patient Identifier as index and delete some columns
df.set_index('patient_identifier',inplace=True)
df.drop(columns = ['Unnamed: 11', 'Unnamed: 12','subject id'],inplace = True)

#Explore the dataset
print("# of Patients:"+str(df.shape[0]))
print("******Understading Features******")
print("# of Electrode:16")
print("\n***Linear Features***")
print("# of Linear Features by emotion (Fear, Happy, Sad, Resting)\n16 Electrodes*8 features :"+str(len([i for i in df.columns if 'lf' in i and 'fear' in i])))
print("# of Total Linear Features\n16 Electrodes*8 features*4 Emotions:"+str(len([i for i in df.columns if 'lf' in i])))
print("\n***Non Linear Features***")
print("# of Non Features by emotion (Fear, Happy, Sad, Resting)\n16 Electrodes*3 features:"+str(len([i for i in df.columns if 'nl' in i and 'fear' in i])))
print("# of Non Linear Features\n:16 Electrodes*3 features*4 Emotions :"+str(len([i for i in df.columns if 'nl' in i])))
print("\n***Rest of the Features***")
print("# of Other Features:"+str(714-len([i for i in df.columns if 'nl' in i or 'lf' in i])))
print("\n***Total Features***")
print("# of Total Features (512+192+10):"+str(df.shape[1]))
df.head()

#Code to build box plots
def box_plot_builder(df,key='age',title_vals = 'Bias in Enrollment'):
  """
  Inputs:
  df - dataframe
  key - On which we need to group by data
  title_vals - Expected title for the chart

  Outputs:
  Box plot
  """
  val = key
  #Build a categorical column as key for the charts
  key = pd.cut(df[key],bins = 5)
  #Let's first find our demographic profile
  temp = df.groupby([key,'type']).count()['lf_beta_fear_E36'].unstack()
  temp.columns = ['Normal','MDD']

  #Preparing data to represent in grouped column chart
  labels = [(round(i.left),round(i.right)) for i in temp.index.categories]
  normal = temp.Normal/np.sum(temp.Normal)
  mdd = temp.MDD/np.sum(temp.MDD)
  x = np.arange(len(labels))  # the label locations
  width = 0.35  # the width of the bars

  fig, ax = plt.subplots()
  rects1 = ax.bar(x - width/2, normal, width, label='HC (29)')
  rects2 = ax.bar(x + width/2, mdd, width, label='MDD (24)')

  # Add some text for labels, title and custom x-axis tick labels, etc.
  ax.set_ylabel('% of patients')
  ax.set_title(title_vals)
  #ax.set_xticks(x, labels)
  ax.set_xlabel(val)
  ax.set_xticks(x) # values
  ax.set_xticklabels(labels) # labels
  ax.legend()

  #save the charts
  fig.tight_layout()

# Define the directory where you want to save the image
  save_directory = 'plots'

# Make sure the directory exists, create it if necessary
  if not os.path.exists(save_directory):
    os.makedirs(save_directory)

# Specify the file name for the saved image (e.g., 'EA_Demog_' + val + '.png')
  file_name = 'EA_Demog_' + val + '.png'

# Combine the directory and file name to get the full path
  path_to_save = os.path.join(save_directory, file_name)

# Save the chart
  fig.savefig(path_to_save, dpi=100)

  plt.show()

df_demog.columns

df_demog.groupby('type').agg({'age' : ['count', 'mean'], 'education（years）' : ['mean'],'CTQ-SF' : 'mean','LES':'mean', 'SSRS':'mean', 'GAD-7':'mean', 'PSQI':'mean'}).to_csv(r"C:\Users\ojasw\OneDrive - vitbhopal.ac.in\Machine Learning\Group Project (290)\images\EA_Participant_summary.csv.xlsx")

#Looping through various demographics columns
for cols in ['age','education（years）', 'PHQ-9','CTQ-SF', 'LES', 'SSRS', 'GAD-7', 'PSQI']:
  box_plot_builder(df,key=cols,title_vals = 'Bias in Enrollment with '+cols)

columns_to_drop = ['age','education（years）', 'PHQ-9','CTQ-SF', 'LES', 'SSRS', 'GAD-7', 'PSQI']

df.columns



#Helper function - Purpose is to extract necessary column from the dataframe as per set initialized and plot correlation map of 16 electodes
#Also provide a view on how they differ between Depression and Normal patient

def columns_extractor(df,emotion,feature_type,name):
  """
  Inputs:
  df - Dataframe that we are using
  emotion - There are four emotions namely : Happy, Fear, Sad and Resting
  Feature - Either Linear feature (lf) or Non-linear features (nl)
  Outputs:
  resultant data frame
  """
  if feature_type =='lf':
    columns_to_extract = [i for i in df.columns if feature_type in i and emotion in i and name in i]
    final_cols = {i:i.replace(feature_type+'_'+name+'_'+emotion+'_', '') for i in columns_to_extract}
  else:
    columns_to_extract = [i for i in df.columns if feature_type in i and name in i and emotion in i]
    final_cols = {i:i.replace(feature_type+'_'+name+emotion+'_', '') for i in columns_to_extract}
  columns_to_extract.extend(['type'])
  #print(columns_to_extract)
  df_result = df[columns_to_extract]
  return df_result.rename(columns = final_cols)

def correlation_builder(df,prefix):
  """
  Inputs:
  df - Dataframe to be used
  Outputs:
  chart object - This will be saved for future reference
  """
  #Correlation cross tab
  corr_all = df[[i for i in df.columns if 'type' not in i]].corr()
  corr_md = df[df['type']=='MDD'][[i for i in df.columns if 'type' not in i]].corr()
  corr_hc = df[df['type']=='HC'][[i for i in df.columns if 'type' not in i]].corr()
  list_corr = [corr_all,corr_md,corr_hc]
  titles = ['All Participants','MDD','HC']
  #Mask for the upper triangle of correlation to be masked
  mask = np.zeros_like(corr_all)
  mask[np.triu_indices_from(mask)] = True
  min = -1
  max = 1
  a = dict()
  fig =  plt.figure(figsize=(30,12))
  for val in range(3):
    with sns.axes_style("white"):
      a[val] = fig.add_subplot(1,3,val+1)
      a[val] = sns.heatmap(list_corr[val], mask=mask, square=True,vmin=min,vmax=max,cmap = sns.cm.rocket_r,
                           cbar_kws = dict(use_gridspec=False,location="bottom"))
      a[val].set_title(titles[val],fontdict={'fontsize': '20', 'fontweight' : '5'})

  #sns.heatmap(arr, ax=ax, cbar_ax = cbar_ax, cbar=True)
  fig.suptitle('Heat Map for '+prefix, fontsize=30)
  path_to_save = 'EA_'+prefix+'.png'
  fig.savefig(path_to_save,dpi = 100)
  return corr_all,fig

def column_eliminator(df,thr=0.9):
  columns = np.full((df.shape[0],), True, dtype=bool)
  for i in range(df.shape[0]):
      for j in range(i+1, df.shape[0]):
          if df.iloc[i,j] >= thr:
              if columns[j]:
                  columns[j] = False
  return columns

emotion = 'fear'
for name in ['max','min','mean','median','alpha','beta','delta','theta']:
  temp = columns_extractor(df,emotion,'lf',name)
  a,b = correlation_builder(temp,prefix = 'Linear feature '+emotion+'_'+name)

columns_to_keep = []
for emotion in ['happy','sad','fear','resting']:
  for name in ['max','min','mean','median','alpha','beta','delta','theta']:
    temp = columns_extractor(df,emotion,'lf',name)
    a,b = correlation_builder(temp, prefix = 'Linear feature '+emotion+'_'+name)
    temp.drop(columns = 'type',inplace=True)
    columns_to_keep.extend(['lf_'+name+'_'+emotion+'_'+i for i in temp.columns[column_eliminator(a,thr = 0.8)]])

len(columns_to_keep)
print(columns_to_keep)

#Lets divide the data set into test and train. Here we have to create a stratified
#sample to create the train and test datasets. While we can use the native SCIKIT learn
#Test, Train splits, we are going to write a custom code here
sample = df.groupby('type', group_keys=False).apply(lambda x: x.sample(round(30*0.7),random_state=42))
left_over = df[~(df.index.isin(list(sample.index)))]

#Lets create the variables for test and train
y = sample['type']
X = sample.drop(columns = 'type')
X_test = left_over.drop(columns = 'type')
y_test = left_over['type']

#Eliminate columns that have more than 0.8 correlation between them
df_pca = df[columns_to_keep]
#df_pca.drop(columns = 'type',inplace = True)
columns_to_consider = list(df_pca.columns[column_eliminator(df_pca.corr(),thr = 0.8)])
#columns_to_consider = list(df_pca.columns)

#Final Set of columns for the exercise - Total of 89 columns were used for this exercise
X = X[columns_to_consider]
X_test = X_test[columns_to_consider]

X_train, X_temp, y_train, y_temp = train_test_split(X,y,  test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)
print(y)

print(X_train[0])

def evaluate_knn(model, X_test, y_test):
    predictions = model.predict(X_test)
    return accuracy_score(y_test, predictions)

feat = []
labels = []

feat.extend(X_train)
feat.extend(X_val)
feat.extend(X_test)

labels.extend(y_train.tolist())
labels.extend(y_val.tolist())
labels.extend(y_test.tolist())

print(len(feat))
print(len(labels))

num_test = 10

for num_neighbours in range(1, 10):
  train_x = feat[num_test:]
  train_y = labels[num_test:]
  test_x = feat[:num_test]
  test_y = labels[:num_test]
  neigh = KNeighborsClassifier(n_neighbors=num_neighbours)
  neigh.fit(train_x, train_y)
  acc = evaluate_knn(neigh, test_x, test_y)
  print(num_neighbours, acc)

# print(neigh.predict([X_test[0]]))
# print(evaluate_knn(neigh, X_test, y_test))
# print(y_test.iloc[0])

from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from statistics import mean

# Merge Datasets
feat = []
labels = []

feat.extend(X_train)
feat.extend(X_val)
feat.extend(X_test)

labels.extend(y_train.tolist())
labels.extend(y_val.tolist())
labels.extend(y_test.tolist())

print(len(feat))
print(len(labels))

# Trying different ML models
models = {}

# 1. Decision Tree Classification
clf = DecisionTreeClassifier(random_state=0)
models['Decision Tree Classification'] = clf

# 2. kNN
neigh = KNeighborsClassifier(n_neighbors=4)
models['kNN Classifier'] = neigh

# 3. SVC (Support Vector Classifier) with Linear Kernel
svc = SVC(kernel = 'linear', random_state = 0)
models['Support Vector Classifier'] = svc

# 4 SVM
svc_rbf = SVC(kernel = 'rbf', random_state = 0)
models['SVM'] = svc_rbf

# 5. Gaussian classifier
nb = GaussianNB()
models['Gaussian classifier'] = nb

# 6. Random forest classifier
rf = RandomForestClassifier(max_depth=2, random_state=0)
models['Random forest classifier'] = rf

# 7. Ada boost classifier
abc = AdaBoostClassifier()
models['Ada boost classifier'] = abc

# 8. Multi-Layer Perceptron
mlp = MLPClassifier(alpha=1, max_iter=1000)
models['Multi-Layer Perceptron'] = mlp

cv = 10
# Running cross validation on all the aove mentioned classifers.
for key, value in models.items():
  cv_results = cross_validate(value, feat, labels, cv=cv, return_train_score=True)
  test_scores = cv_results['test_score']
  avg_score = mean(test_scores)
  max_score = max(test_scores)
  print("For", key)
  print('Cross Validation Scores:', test_scores)
  print('Mean Validation Score:', avg_score)
  print('Max Validation Score:', max_score)
  print()


# cv_results = cross_validate(clf, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# avg_score = mean(test_scores)
# max_score = max(test_scores)
# print("For Decision Tree Classifier:")
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)
# print()

# cv_results = cross_validate(neigh, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# print("For Decision Tree Classifier:")
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)
# print()

# cv_results = cross_validate(svc, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# print("For Decision Tree Classifier:")
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)
# print()

# cv_results = cross_validate(svc_rbf, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# print("For Decision Tree Classifier:")
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)
# print()

# cv_results = cross_validate(nb, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# print("For Decision Tree Classifier:")
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)
# print()

# cv_results = cross_validate(rf, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)

# cv_results = cross_validate(abc, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)

# cv_results = cross_validate(mlp, feat, labels, cv=cv, return_train_score=True)
# test_scores = cv_results['test_score']
# print('Cross Validation Scores:', test_scores)
# print('Mean Validation Score:', avg_score)
# print('Max Validation Score:', max_score)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
import numpy as np

# Reshaping the data
X_train = np.array(X_train)  # Convert X_train to a numpy array
y_train = np.array(y_train)  # Convert y_train to a numpy array

# Define the model
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Accuracy: {accuracy}')

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(53,)),  # Replace 'input_shape' with the number of EEG features
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the Model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the Model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-Score: {f1}")

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Assuming you have loaded and preprocessed your EEG data into X and labels
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Adjust input shape
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the Model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the Model
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))

# Evaluate the Model
y_pred = (model.predict(X_test) > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1)

from tensorflow import keras
model = keras.Sequential([
    tf.keras.layers.Input(shape=(53,)),  # Replace with the appropriate input shape
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy}")

import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Define your model
model = models.Sequential([
    layers.Input(shape=(53,)),  # Adjust input shape based on your EEG features
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),  # Add dropout for regularization
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # Binary classification
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Define early stopping to prevent overfitting
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,  # Adjust patience based on your needs
    restore_best_weights=True
)

# Train the model
history = model.fit(X_train, y_train,
                    validation_data=(X_val, y_val),
                    epochs=100,  # You can adjust the number of epochs
                    callbacks=[early_stopping])

# Evaluate the model on the test set
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

test_accuracy = accuracy_score(y_test, y_pred_binary)
test_precision = precision_score(y_test, y_pred_binary)
test_recall = recall_score(y_test, y_pred_binary)
test_f1_score = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {test_accuracy}")
print(f"Test Precision: {test_precision}")
print(f"Test Recall: {test_recall}")
print(f"Test F1-Score: {test_f1_score}")

import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler

# Define a learning rate schedule
def lr_schedule(epoch):
    if epoch < 50:
        return 0.001
    elif epoch < 100:
        return 0.0001
    else:
        return 0.00001

# Define your model
model = models.Sequential([
    layers.Input(shape=(53,)),  # Adjust input shape based on your EEG features
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # Binary classification
])

# Compile the model with a custom optimizer and learning rate schedule
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule(0))
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Define early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)

# Train the model with the updated learning rate schedule
history = model.fit(X_train, y_train,
                    validation_data=(X_val, y_val),
                    epochs=150,  # Increase the number of epochs
                    callbacks=[early_stopping, LearningRateScheduler(lr_schedule)])

# Evaluate the model on the test set
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

test_accuracy = accuracy_score(y_test, y_pred_binary)
test_precision = precision_score(y_test, y_pred_binary)
test_recall = recall_score(y_test, y_pred_binary)
test_f1_score = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {test_accuracy}")
print(f"Test Precision: {test_precision}")
print(f"Test Recall: {test_recall}")
print(f"Test F1-Score: {test_f1_score}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Define your model architecture
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(53,)))
model.add(Dropout(0.5))  # Add dropout layer
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model with a lower learning rate
opt = Adam(learning_rate=0.001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {test_accuracy}')

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,  # Increase the patience value
    restore_best_weights=True
)

# Train the Model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,  # Increase the patience value
    restore_best_weights=True
)

# Train the Model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,  # Increase the patience value
    restore_best_weights=True
)

# Train the Model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,  # Increase the patience value
    restore_best_weights=True
)

# Train the Model with a higher number of epochs
model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,  # Increase the patience value if needed
    restore_best_weights=True
)

# Train the Model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,  # Increase the patience value if needed
    restore_best_weights=True
)

# Train the Model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=30,  # Increase the patience value if needed
    restore_best_weights=True
)

# Train the Model
model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler

# Load your EEG data and labels (replace with your data loading code)
# X = ...  # EEG data (features)
# labels = ...  # Depression labels (0 or 1)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Normalize EEG data within the range [0, 1]
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Build a Deep Learning Model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input shape matching the number of EEG features
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (depressed or not)
])

# Compile the Model with a lower learning rate
opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Implement early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=30,  # Increase the patience value if needed
    restore_best_weights=True
)

# Train the Model
model.fit(X_train, y_train, epochs=150, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping])

# Evaluate the Model
y_pred = model.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

print(f"Test Accuracy: {accuracy}")
print(f"Test Precision: {precision}")
print(f"Test Recall: {recall}")
print(f"Test F1-Score: {f1}")
